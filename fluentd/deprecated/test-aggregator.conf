<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<source>
  @type tail
  <parse>
    @type json
  </parse>
  path /var/log/test-service/*.log
  pos_file /var/log/test-service/data.log.pos
  tag model.test
</source>

<filter model.test>
  @type grep
  <regexp>
    key message
    pattern /model_predicts/
  </regexp>
</filter>

<filter model.test>
  @type record_transformer
  enable_ruby
  <record>
    hostname "#{Socket.gethostname}"
    tag ${tag}
    message ${record["message"].gsub("model_predicts:", "")}
  </record>
</filter>

<filter model.test>
  @type            elasticsearch_genid
  hash_id_key      _hash    # storing generated hash id key (default is _hash)
</filter>

<match model.test>
  @type stdout
  @type copy
  <store>
    @type stdout
  </store>
  <store>
    @type elasticsearch
    host <host>
    port <port>
    # user <user>
    # password <password>
    # scheme https
    # ssl_verify false
    id_key             _hash # specify same key name which is specified in hash_id_key
    remove_keys        _hash # Elasticsearch doesn't like keys that start with _
    logstash_format true
    logstash_prefix fluentd2-${tag}
    include_tag_key true
    time_key log_time
    type_name _doc
    request_timeout    30s
    slow_flush_log_threshold 30s
    <buffer>
      @type            file
      path             "/var/log/test/buffer"
      total_limit_size 1G
      chunk_limit_size 15M
      flush_interval   30s
      retry_wait       10.0
    </buffer>
  </store>
</match>