<source>
  @type forward
  port 24224
  bind 0.0.0.0
  <format>
    @type json
  </format>
</source>

<match fluent.info>
  @type stdout
</match>

<filter model.*>
  @type            elasticsearch_genid
  hash_id_key      _hash    # storing generated hash id key (default is _hash)
</filter>

# save model log result to elasticsearch
<match model.*>
  @type copy
  <store>
  @type http
    endpoint_url   http://web:8080/publish
    ssl_no_verify   false  # default: false
    http_method     post    # default: post
    serializer      json   # default: form
    flush_interval 10s
  </store>
  <store>
    @type stdout
  </store>

  # <store>
  #   @type elasticsearch
  #   host <host>
  #   port <port>
  #   # user <user>
  #   # password <password>
  #   # scheme https
  #   # ssl_verify false
  #   id_key             _hash # specify same key name which is specified in hash_id_key
  #   remove_keys        _hash # Elasticsearch doesn't like keys that start with _
  #   logstash_format true
  #   logstash_prefix fluentd-${tag}
  #   include_tag_key true
  #   time_key log_time
  #   type_name _doc
  #   request_timeout    30s
  #   slow_flush_log_threshold 30s
  #   <buffer>
  #     @type            file
  #     path             "/var/log/test/buffer"
  #     total_limit_size 1G
  #     chunk_limit_size 15M
  #     flush_interval   20s
  #     retry_wait       10.0
  #   </buffer>
  # </store>
</match>

# save azure entity result to redis and mongodb
# <match azure.ner>
#   @type copy
#   <store>
#     @type stdout
#   </store>
#   <store>
#     @type mongo
#     host mongodb
#     port 27017
#     database fluentd_ai
#     collection ner_collection
#     <inject>
#     time_key time
#     </inject>
#     <buffer>
#       flush_interval 20s
#     </buffer>
#   </store>
#   <store>
#     @type redis_store
#     host redis
#     port 6379
#     db 1
#     key_path data.name
#     key_expire 1209600
#     <buffer>
#       flush_interval 20s
#     </buffer>
#   </store>
# </match>
