<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<match fluent.info>
  @type stdout
</match>

<filter model.*>
  @type            elasticsearch_genid
  hash_id_key      _hash    # storing generated hash id key (default is _hash)
</filter>

# save model log result to elasticsearch
<match model.*>
  @type copy
  <store>
    @type stdout
  </store>
  <store>
    @type elasticsearch
    host <host>
    port <port>
    # user <user>
    # password <password>
    # scheme https
    # ssl_verify false
    id_key             _hash # specify same key name which is specified in hash_id_key
    remove_keys        _hash # Elasticsearch doesn't like keys that start with _
    logstash_format true
    logstash_prefix fluentd-${tag}
    include_tag_key true
    time_key log_time
    type_name _doc
    request_timeout    30s
    slow_flush_log_threshold 30s
    <buffer>
      @type            file
      path             "/var/log/test/buffer"
      total_limit_size 1G
      chunk_limit_size 15M
      flush_interval   20s
      retry_wait       10.0
    </buffer>
  </store>
</match>

# save azure entity result to redis and mongodb
<match azure.ner>
  @type copy
  <store>
    @type stdout
  </store>
  <store>
    @type mongo
    host mongodb
    port 27017
    database fluentd_ai
    collection ner_collection
    <inject>
    time_key time
    </inject>
    <buffer>
      flush_interval 20s
    </buffer>
  </store>
  <store>
    @type redis_store
    host redis
    port 6379
    db 1
    key_path data.name
    key_expire 1209600
    <buffer>
      flush_interval 20s
    </buffer>
  </store>
</match>

